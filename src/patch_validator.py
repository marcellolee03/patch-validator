from LLM_patch_generation.args_parser import parse_arguments_validator
from LLM_patch_generation.generator_utils import ask_LLM
from LLM_patch_generation.extract_info.env_scanner import extract_environment_info
from LLM_patch_generation.extract_info.container_scanner import extract_container_info, list_containers
from LLM_patch_generation.validator_utils import search_for, generate_validator_prompt
from LLM_patch_generation.extract_info.vuln_details_extractor import extract_vulnerability_details
from os import mkdir
import time

# LLM model tasked to validate generated correction patches
VALIDATOR_MODEL = "gpt-5.1"
VALIDATOR_OUTPUT_DIR = "validator_output"

def main():
    # Setting directory containing correction patches
    args = parse_arguments_validator()
    patches_filepath = args.Patches_directory_filepath
    report_filepath = args.report_filepath

    # Specifying targeted vulnerability 
    print('Identifying vulnerability...')
    try:
        with open(f'{patches_filepath}/gemini-2.5-flash_details.txt', 'r') as f:
            for line in f:
                if line.startswith('NVT OID:'):
                    nvt_oid = line.split(':', 1)[1].strip()
                    break
    except FileNotFoundError:
        print("Could not find directory containing correction patches. Ending program.")
        return

    # Fetching OpenVAS report
    print('Fetching OpenVAS report...')
    try:
        VULN_DETAILS = extract_vulnerability_details(report_filepath, nvt_oid)
    except FileNotFoundError:
        print(f'Could not find OpenVAS report in {report_filepath}. Ending program.')
        return

    # Setting ENVIRONMENT INFORMATION for environment where vulnerability is located
    valid_user_input = False
    while not valid_user_input:
        user_input = input('Is vulnerability found in a Docker Container [Y/n]? ')
        match user_input.lower():
            case 'y':
                vuln_in_container = True
                valid_user_input = True
            case 'n':
                vuln_in_container = False
                valid_user_input = True
            case _:
                pass


    print('Extracting environment information...')
    with open('env.txt', 'r', encoding='utf-8') as file:
        test_environments = json.load(file)
    
    if vuln_in_container:
        # Deactivated for testing:
        
        '''
        if vuln_in_container:
            active_containers = list_containers()
            
            print('Select container from list: ')
            for container in active_containers:
                print(f'- {container}')
            
            valid_user_input = False
            while not valid_user_input:
                user_input = input()

                if user_input in active_containers:
                    env_info = extract_container_info(user_input)
                    valid_user_input = True
                else:
                    print('Invalid input. Select container from list')
        '''
        try:
            ENVIRONMENT_INFORMATION = test_environments[nvt_oid]['env_info']
        except KeyError:
            print(f'Could not find {nvt_oid} NVT OID in env.txt. Ending program.')
            return
    else:
        try:
            ENVIRONMENT_INFORMATION = test_environments['pop-os-24-ambient']['env_info']
        except KeyError:
            print(f'Could not find pop-os-24-ambient in env.txt. Ending program.')
            return


    # Gathering cheatsheet content, including solution
    print('Locating vulnerability in cheatsheet...')
    with open('cheatsheet.txt', 'r', encoding='utf-8') as file:
        cheatsheet = json.load(file)
    try:
        VULNERABILITY_CHEATS = cheatsheet[nvt_oid]['recomended_correction_script']
    except KeyError:
        printf(f'Could not find {nvt_oid} in cheatsheet. Ending program')
        return
    
    # Storing all generated correction patches in a single variable
    print('Gathering generated correction patches...')
    MODELS = ['gemini-2.5-flash', 'gemini-3-flash', 'deepseek-V3.1']
    patches = {}

    for model in MODELS:
        try:
            with open(f'{patches_filepath}/{model}_patch.sh', 'r') as f:
                content = f.read()
                patches[model] = content
        except FileNotFoundError:
            print(f"Could not find correction patch generated by {model}. Ending program.")
            return
    
    GENERATED_CORRECTION_PATCHES = ''
    GENERATED_CORRECTION_PATCHES +=  f'===============================================================================\n'
    for model, patch in patches.items():
        GENERATED_CORRECTION_PATCHES +=  f'CORRECTION PATCH GENERATED BY {model}:\n\n'
        GENERATED_CORRECTION_PATCHES +=  f'{patch}\n'
        GENERATED_CORRECTION_PATCHES +=  f'===============================================================================\n'
    
    # Fully assembling prompt to feed the validator
    validator_prompt = generate_validator_prompt(ENVIRONMENT_INFORMATION, VULN_DETAILS, VULNERABILITY_CHEATS, GENERATED_CORRECTION_PATCHES)

    timer_start = time.perf_counter()

    # Sending prompt to validator API
    print(f"Requesting verdict from {VALIDATOR_MODEL}...")
    response = ask_LLM("gpt-5.1", validator_prompt)

    if response.status == "ERR":
        print(f"ERROR while fetching response. Shutting down script.")
        print(f"ERROR details: {response.content}")
        return

    timer_end = time.perf_counter()
    elapsed_time = (timer_end - timer_start)
    
    # Saving validator verdict
    print("Saving validator output...")
    try:
        mkdir(VALIDATOR_OUTPUT_DIR)
    except FileExistsError:
        pass

    filename = f"{TARGET_VULNEARBILITY}_verdict.txt"

    with open(f"{VALIDATOR_OUTPUT_DIR}/{filename}", "w") as f:
        f.write(response.content)
        f.write(f"\n\nELAPSED TIME: {elapsed_time}")
        print(f"Verdict successfully saved at {VALIDATOR_OUTPUT_DIR}/{filename}!")

    
if __name__ == '__main__':
   main()
